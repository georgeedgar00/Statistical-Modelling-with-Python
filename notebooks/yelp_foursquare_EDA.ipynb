{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e5d828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\goerge\\anaconda3\\lib\\site-packages (1.25.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2441763",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.7 from \"C:\\Users\\Goerge\\anaconda3\\envs\\perm_enviro\\python.exe\"\n  * The NumPy version is: \"1.21.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed: The specified module could not be found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13132\\2616470767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\perm_enviro\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     raise ImportError(\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;34m\"Unable to import required dependencies:\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     )\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.7 from \"C:\\Users\\Goerge\\anaconda3\\envs\\perm_enviro\\python.exe\"\n  * The NumPy version is: \"1.21.5\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed: The specified module could not be found.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186a2d4",
   "metadata": {},
   "source": [
    "# Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26726736",
   "metadata": {},
   "source": [
    "Send a request to Foursquare with a small radius (1000m) for all the bike stations in your city of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1503213",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('df_city_bike.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
    "# creation of variable with lon and lat together\n",
    "data['ll'] = data['latitude'].astype(str) + ',' + data['longitude'].astype(str)\n",
    "data = data[data['ll'] != '0.0,0.0']\n",
    "\n",
    "#list of longitude and latitude from bike station dataframe\n",
    "bike_ll = list(set(data['ll']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed0f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace , so we can add the ll of stations to URL\n",
    "bike_stop_ll = [s.replace(',', '%2C') for s in bike_ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a67bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# went to https://location.foursquare.com/developer/reference/place-search and \n",
    "# https://location.foursquare.com/developer/reference/response-fields to check how API call should be made\n",
    "# checked categories https://location.foursquare.com/places/docs/categories\n",
    "\n",
    "#set the key\n",
    "api_key = os.environ[\"FOURSQUARE_KEY\"]\n",
    "\n",
    "# Create dictionary for headers\n",
    "headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "# Add key with our API KEY\n",
    "headers['Authorization'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94766a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "foursquare_list_rich_20 = []\n",
    "\n",
    "# Getting data for places around bike stops\n",
    "for station in bike_stop_ll:\n",
    "    try:\n",
    "        url = \"https://api.foursquare.com/v3/places/search?radius=1000&fields=categories%2Crating%2Cgeocodes%2Ccategories%2Clocation%2Cname%2Cfsq_id%2Cstats%2Cprice&limit=20&ll=\" + station\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            foursquare_list_rich_20.append(response.json())\n",
    "        else:\n",
    "            print('Error occurred during the API request')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if e == \"Quota exceeded\":\n",
    "            print(\"Exceeded quota: waiting for an hour\")\n",
    "            time.sleep(3600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e75d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foursquare_20 = pd.DataFrame(columns=['row_from_station', 'fsq_id', 'category_id', 'name', 'latitude', 'longitude', 'rating', 'total_ratings', 'total_photos', 'total_tips'])\n",
    "\n",
    "for station in range(len(foursquare_list_rich_20)):\n",
    "    for result in range(len(foursquare_list_rich_20[station]['results'])):\n",
    "        if 'fsq_id' in foursquare_list_rich_20[station]['results'][result]:\n",
    "            fsq_id = foursquare_list_rich_20[station]['results'][result]['fsq_id']\n",
    "        else:\n",
    "            fsq_id = None\n",
    "            \n",
    "        if 'categories' in foursquare_list_rich_20[station]['results'][result] and len(foursquare_list_rich_20[station]['results'][result]['categories']) > 0:\n",
    "            category_id = foursquare_list_rich_20[station]['results'][result]['categories'][0].get('id', None)\n",
    "        else:\n",
    "            category_id = None\n",
    "            \n",
    "        if 'name' in foursquare_list_rich_20[station]['results'][result]:\n",
    "            name = foursquare_list_rich_20[station]['results'][result]['name']\n",
    "        else:\n",
    "            name = None\n",
    "            \n",
    "        if 'geocodes' in foursquare_list_rich_20[station]['results'][result] and 'main' in foursquare_list_rich_20[station]['results'][result]['geocodes']:\n",
    "            latitude = foursquare_list_rich_20[station]['results'][result]['geocodes']['main'].get('latitude', None)\n",
    "            longitude = foursquare_list_rich_20[station]['results'][result]['geocodes']['main'].get('longitude', None)\n",
    "        else:\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "            \n",
    "        if 'rating' in foursquare_list_rich_20[station]['results'][result]:\n",
    "            rating = foursquare_list_rich_20[station]['results'][result]['rating']\n",
    "        else:\n",
    "            rating = None\n",
    "            \n",
    "        if 'stats' in foursquare_list_rich_20[station]['results'][result]:\n",
    "            total_ratings = foursquare_list_rich_20[station]['results'][result]['stats'].get('total_ratings', None)\n",
    "            total_photos = foursquare_list_rich_20[station]['results'][result]['stats'].get('total_photos', None)\n",
    "            total_tips = foursquare_list_rich_20[station]['results'][result]['stats'].get('total_tips', None)\n",
    "        else:\n",
    "            total_ratings = None\n",
    "            total_photos = None\n",
    "            total_tips = None\n",
    "        \n",
    "        df_foursquare_20 = df_foursquare_20.append({\n",
    "            'row_from_station': station,\n",
    "            'fsq_id': fsq_id,\n",
    "            'category_id': category_id,\n",
    "            'name': name,\n",
    "            'latitude': latitude,\n",
    "            'longitude': longitude,\n",
    "            'rating': rating,\n",
    "            'total_ratings': total_ratings,\n",
    "            'total_photos': total_photos,\n",
    "            'total_tips': total_tips\n",
    "        }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc1ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#foursquare_list (foursquare_basic.js) is a file that has only the basic information about business\n",
    "\n",
    "#foursquare_list_rich_50 (foursquare_50.js) is file that has the same code block as foursquare_rich_20, except limit for number of businesses was 50\n",
    "# df_foursquare_50.csv is dataframe for same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68131914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I already made DataFrame when parsing through foursquare json file\n",
    "\n",
    "df_foursquare_20.to_csv('df_foursquare_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visited https://docs.developer.yelp.com/reference/v3_business_search to check API structure\n",
    "\n",
    "#set the key\n",
    "yelp_api_key = os.environ[\"YELP_KEY\"]\n",
    "\n",
    "# Create dictionary for headers\n",
    "headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "# Add key with our API KEY\n",
    "headers['Authorization'] = yelp_api_key\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + yelp_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_list = []\n",
    "\n",
    "# Getting data for places around bike stops\n",
    "for index in range(len(bike_stop_ll)):\n",
    "    try:\n",
    "        latitude = data.iloc[index][\"latitude\"]\n",
    "        longitude = data.iloc[index][\"longitude\"]\n",
    "        yelp_url = \"https://api.yelp.com/v3/businesses/search?latitude=\" + str(latitude) + \"&longitude=\" + str(longitude) + \"&term=park&radius=1000&categories=&sort_by=best_match&limit=20\"\n",
    "        yelp_response = requests.get(yelp_url, headers=headers)\n",
    "        \n",
    "        if yelp_response.status_code == 200:\n",
    "            yelp_list.append(yelp_response.json())\n",
    "        else:\n",
    "            print('Error occurred during the API request')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        if e == \"Quota exceeded\":\n",
    "            print(\"Exceeded quota: waiting for an hour\")\n",
    "            time.sleep(3600)\n",
    "\n",
    "# Save yelp_list as a JavaScript file\n",
    "file_path = \"yelp_list.js\"\n",
    "\n",
    "with open(file_path, \"w\") as js_file:\n",
    "    js_file.write(\"var yelpList = \")\n",
    "    json.dump(yelp_list, js_file)\n",
    "\n",
    "print(\"yelp_list saved as js file: \" + file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = pd.DataFrame(columns=['row_from_station', 'id', 'name', 'rating', 'review_count', 'latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing through 'yelp_list' from previous step to get columns for dataframe (id, name, rating, review_count, latitude and longitude)\n",
    "for station in range(len(yelp_list)):\n",
    "    for business in range(len(yelp_list[station]['businesses'])):\n",
    "        df_yelp = df_yelp.append({\n",
    "            'row_from_station': station,\n",
    "            'id': yelp_list[station]['businesses'][business]['id'],\n",
    "            'name': yelp_list[station]['businesses'][business]['name'],\n",
    "            'rating': yelp_list[station]['businesses'][business]['rating'],\n",
    "            'review_count': yelp_list[station]['businesses'][business]['review_count'],\n",
    "            'latitude': yelp_list[station]['businesses'][business]['coordinates']['latitude'],\n",
    "            'longitude': yelp_list[station]['businesses'][business]['coordinates']['longitude']\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc68c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking shape and first 5 rows of dataframe\n",
    "print(df_yelp.shape)\n",
    "print(df_yelp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c262959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate rows\n",
    "df_foursquare_20_clean = df_foursquare_20.drop_duplicates(subset=[\"fsq_id\"], keep='first')\n",
    "df_yelp_clean = df_yelp.drop_duplicates(subset=[\"id\"], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517765f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foursquare_filter = df_foursquare_20_clean[\n",
    "    (df_foursquare_20_clean.apply(lambda row: row.astype(str).str.contains('Parc', case=False).any(), axis=1)) &\n",
    "    (df_foursquare_20_clean['total_ratings'] > 10)\n",
    "]\n",
    "print('Mean for total ratings is: ' + str(df_foursquare_filter['total_ratings'].mean()))\n",
    "df_foursquare_filter.sort_values(by=\"rating\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81cac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp_clean_filter = df_yelp_clean.query('review_count > 10')\n",
    "print(\"Mean for review_count is: \" + str(df_yelp_clean_filter['review_count'].mean()))\n",
    "df_yelp_clean.query('review_count > 10').sort_values(by=\"rating\", ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perm_enviro",
   "language": "python",
   "name": "perm_enviro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
